{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2258,"status":"ok","timestamp":1713540718691,"user":{"displayName":"Myo Thiha","userId":"00141362449010417331"},"user_tz":-120},"id":"avYA7wew5HSY","outputId":"1def0b79-e63e-4702-8a58-8071354eb516"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uzRmLRUm5JnE"},"outputs":[],"source":["dataset_path = \"/content/drive/MyDrive/Colab_Notebooks/NLP/Project/datasets/relevantQA_dataset.csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yKIowSk35iuP"},"outputs":[],"source":["!cp $dataset_path ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MVLdWWRI5CGG"},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader, random_split, Dataset\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n","from torch.optim import AdamW\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import LabelEncoder\n","import pandas as pd\n","import numpy as np\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_YvtXWrE5CGI"},"outputs":[],"source":["# Load your CSV dataset (replace with your actual dataset path)\n","df = pd.read_csv(\"relevantQA_dataset.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"neDvdJA35CGI"},"outputs":[],"source":["# df['relevant'] = df['relevant'].str.lower()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1713540722722,"user":{"displayName":"Myo Thiha","userId":"00141362449010417331"},"user_tz":-120},"id":"KLgdBXQ_5CGJ","outputId":"5bcf1ef6-3969-4c42-a763-efcf77e88653"},"outputs":[{"data":{"text/plain":["array(['relevant', 'irrelevant'], dtype=object)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df['relevant'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VVUT8Ilf5CGJ"},"outputs":[],"source":["relevant_encoder = LabelEncoder()\n","df['label'] = relevant_encoder.fit_transform(df['relevant'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1713540722723,"user":{"displayName":"Myo Thiha","userId":"00141362449010417331"},"user_tz":-120},"id":"QFDCFnns5CGK","outputId":"2f6496e1-ee61-469f-cf2f-a3001fd1258f"},"outputs":[{"data":{"text/plain":["array(['irrelevant', 'relevant'], dtype=object)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["relevant_encoder.classes_"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1713540722723,"user":{"displayName":"Myo Thiha","userId":"00141362449010417331"},"user_tz":-120},"id":"Fst3GdQ21uMS","outputId":"8136fb5e-d440-4e20-b8d3-09f523783a63"},"outputs":[{"data":{"text/plain":["array(['irrelevant'], dtype=object)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["relevant_encoder.inverse_transform([0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yd2CYRuw6reL"},"outputs":[],"source":["# df = df.iloc[:1000]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1713540722723,"user":{"displayName":"Myo Thiha","userId":"00141362449010417331"},"user_tz":-120},"id":"38dKDVQw5CGK","outputId":"e409d600-902e-422d-a422-26289ae4a904"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"df\",\n  \"rows\": 85026,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 83405,\n        \"samples\": [\n          \"Measures to contain the global COVID-19 pandemic led to stay-at-home orders across the world, accompanied by fears of a global surge in intimate partner violence (IPV). We administered an online general-population survey to 1169 women and transgender/nonbinary individuals throughout the state of Michigan in June\\u2013August 2020 to assess changes in the prevalence, severity, and correlates of IPV during the COVID-19 pandemic. Quota sampling was used to match the racial/ethnic and urban/rural distribution of the state. More than one in seven (15.1%) participants reported physical, sexual, psychological, or technology-facilitated IPV since COVID, similar to the prevalence in the 3 months before COVID (16.2%). However, there were indications that IPV severity increased and that novel cases of IPV are occurring in relationships that previously had no abuse. A majority (64.2%) of individuals who experienced IPV since COVID reported that the IPV was new to the relationship (34.1%) or of increased severity during COVID-19 (26.6%), representing 9.7% of the overall sample. New or increased IPV was significantly more prevalent among those who were essential workers, pregnant, unable to afford rent, unemployed/underemployed or had recent changes to their job, had partners with recent changes to employment, and those who had gotten tested or tested positive for COVID-19. Urban residence, trans/nonbinary identity, and having a toddler were more strongly associated with IPV during COVID as compared to before COVID. While findings do not support significant changes in the overall prevalence of IPV, the majority of survivors reported incident IPV in relationships that had not previously been abusive, or IPV that became more severe since the start of the pandemic. Cases of new or increased IPV were more concentrated in marginalized groups. Potential touchpoints for outreach and services during future lockdowns include prenatal and pediatric settings, daycares, employers of essential workers, and COVID-19 testing centers. Policies providing rental, childcare, and unemployment support may mitigate increases in IPV during COVID-19.\",\n          \"What did VLP stand for in English-speaking countries?\",\n          \"my husband is 72 years of age and has heart trouble he is on a lot of medication blood thinners etc and has 8 stents in his heart in the last few months he gas had bouts of losing the power n his leg plus a weak feeling in both legs can you help me\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relevant\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"irrelevant\",\n          \"relevant\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"df"},"text/html":["\n","  <div id=\"df-5f83929b-8de8-4d98-84be-9618d2632e11\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>relevant</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>What information is accessible on idiopathic p...</td>\n","      <td>relevant</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>BACKGROUND: Although RT-qPCR remains the gold-...</td>\n","      <td>relevant</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hyperinsulinemia has a negative effect on the ...</td>\n","      <td>irrelevant</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Hi, Dr. Narasi. Thank you for your time. I suf...</td>\n","      <td>relevant</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Hi I have been taking Yaz however I have not c...</td>\n","      <td>relevant</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f83929b-8de8-4d98-84be-9618d2632e11')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5f83929b-8de8-4d98-84be-9618d2632e11 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5f83929b-8de8-4d98-84be-9618d2632e11');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-aa20f607-22d7-4c31-bcef-8cfced72a755\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa20f607-22d7-4c31-bcef-8cfced72a755')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-aa20f607-22d7-4c31-bcef-8cfced72a755 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                                            question    relevant  label\n","0  What information is accessible on idiopathic p...    relevant      1\n","1  BACKGROUND: Although RT-qPCR remains the gold-...    relevant      1\n","2  Hyperinsulinemia has a negative effect on the ...  irrelevant      0\n","3  Hi, Dr. Narasi. Thank you for your time. I suf...    relevant      1\n","4  Hi I have been taking Yaz however I have not c...    relevant      1"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"slm0Lcon5CGK"},"outputs":[],"source":["def load_data_from_csv(df, text_column, label_column):\n","    texts = df[text_column].tolist()\n","    labels = df[label_column].tolist()\n","\n","    return texts, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RbZsZWh_5CGK"},"outputs":[],"source":["texts, labels = load_data_from_csv(df, 'question', 'label')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1713540722724,"user":{"displayName":"Myo Thiha","userId":"00141362449010417331"},"user_tz":-120},"id":"xKYJIlv_3MDP","outputId":"73f37aa8-221d-4af4-994e-f017a3ed08a0"},"outputs":[{"data":{"text/plain":["{0, 1}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["set(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gJ-PiOrQ5CGL"},"outputs":[],"source":["# Dataset class\n","class TextDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_len):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        text = str(self.texts[item])\n","        label = self.labels[item]\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            padding='max_length',\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","            truncation=True,\n","        )\n","        return {\n","            'text': text,\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'labels': torch.tensor(label, dtype=torch.long)\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2811,"status":"ok","timestamp":1713540725518,"user":{"displayName":"Myo Thiha","userId":"00141362449010417331"},"user_tz":-120},"id":"hUJB-rEe5CGL","outputId":"1b76d52c-ae27-4cf0-c3a3-91a1025706a7"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","max_len = 128  # Maximum length of tokens\n","dataset = TextDataset(texts, labels, tokenizer, max_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Fug_8-35CGM"},"outputs":[],"source":["def create_data_loaders(dataset, batch_size):\n","    train_size = int(0.8 * len(dataset))\n","    val_size = int(0.1 * len(dataset))\n","    test_size = len(dataset) - train_size - val_size\n","    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","    return train_loader, val_loader, test_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FaNzOAzr5CGM"},"outputs":[],"source":["batch_size = 200\n","train_data_loader, val_data_loader, test_data_loader = create_data_loaders(dataset, batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OV3XPzFp5CGM"},"outputs":[],"source":["def initialize_model(device):\n","    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n","    model = model.to(device)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1475,"status":"ok","timestamp":1713540726990,"user":{"displayName":"Myo Thiha","userId":"00141362449010417331"},"user_tz":-120},"id":"nXrHCvSY5CGM","outputId":"04b3e910-15be-4c38-f85c-d475918b514c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = initialize_model(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5OD8oyY27e4l"},"outputs":[],"source":["def format_time(seconds):\n","    \"\"\"Converts seconds to a string of hours, minutes, and seconds\"\"\"\n","    hours = seconds // 3600\n","    minutes = (seconds % 3600) // 60\n","    seconds = seconds % 60\n","    return f\"{int(hours)}h {int(minutes)}m {int(seconds)}s\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MsXQsKyR5CGN"},"outputs":[],"source":["import time\n","\n","model_directory = \"./relevantQA_bert\"\n","\n","def train_model(model, train_loader, val_loader, device, n_epochs=3):\n","\n","    optimizer = AdamW(model.parameters(), lr=2e-5)\n","\n","    prev_val_accuracy = 0\n","    for epoch in range(n_epochs):\n","\n","        start_time = time.time()  # Record the start time of the epoch\n","\n","        total_acc = 0\n","        for batch in train_loader:\n","            model.train()\n","            batch_input_ids = batch['input_ids'].to(device)\n","            batch_attention_mask = batch['attention_mask'].to(device)\n","            batch_labels = batch['labels'].to(device)\n","            optimizer.zero_grad()\n","            outputs = model(batch_input_ids, attention_mask=batch_attention_mask, labels=batch_labels)\n","            loss = outputs[0]\n","            loss.backward()\n","            optimizer.step()\n","\n","            model.eval()\n","            outputs = model(batch_input_ids, attention_mask=batch_attention_mask)\n","            logits = outputs[0]\n","            preds = torch.argmax(logits, dim=1)\n","            total_acc += (preds == batch_labels).sum().item()\n","\n","        model.eval()\n","        total_eval_accuracy = 0\n","        for batch in val_loader:\n","            batch_input_ids = batch['input_ids'].to(device)\n","            batch_attention_mask = batch['attention_mask'].to(device)\n","            batch_labels = batch['labels'].to(device)\n","            with torch.no_grad():\n","                outputs = model(batch_input_ids, attention_mask=batch_attention_mask)\n","                logits = outputs[0]\n","                preds = torch.argmax(logits, dim=1)\n","                total_eval_accuracy += (preds == batch_labels).sum().item()\n","\n","        # Calculate the duration of the epoch\n","        end_time = time.time()\n","        epoch_duration = end_time - start_time\n","        formatted_time = format_time(epoch_duration)\n","\n","        avg_val_accuracy = total_eval_accuracy / len(val_loader.dataset)\n","        avg_train_acc = total_acc / len(train_loader.dataset)\n","        print(f\"Epoch {epoch+1}, Acc: {avg_train_acc:.2f} | Validation acc: {avg_val_accuracy:.2f} | Duration: {formatted_time}\")\n","\n","        # Save model and tokenizer after we got better val loss.\n","        delta = 0.0001\n","        if avg_val_accuracy > prev_val_accuracy:\n","          print(f\"{avg_val_accuracy:.4f} > {prev_val_accuracy:.4f}. Saving the model.\")\n","          model.save_pretrained(model_directory)\n","          tokenizer.save_pretrained(model_directory)\n","          prev_val_accuracy = avg_val_accuracy\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"YNnM5f695CGN","outputId":"7ab85e0d-dc14-4f5e-adf6-a069f15b5238"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1, Acc: 0.99 | Validation acc: 1.00 | Duration: 0h 8m 17s\n","0.9964 > 0.0000. Saving the model.\n","Epoch 2, Acc: 1.00 | Validation acc: 1.00 | Duration: 0h 8m 16s\n","Epoch 3, Acc: 1.00 | Validation acc: 1.00 | Duration: 0h 8m 16s\n","Epoch 4, Acc: 1.00 | Validation acc: 1.00 | Duration: 0h 8m 17s\n","0.9972 > 0.9964. Saving the model.\n","Epoch 5, Acc: 1.00 | Validation acc: 0.99 | Duration: 0h 8m 17s\n","Epoch 6, Acc: 1.00 | Validation acc: 1.00 | Duration: 0h 8m 16s\n","Epoch 7, Acc: 1.00 | Validation acc: 1.00 | Duration: 0h 8m 16s\n","Epoch 8, Acc: 1.00 | Validation acc: 1.00 | Duration: 0h 8m 16s\n","Epoch 9, Acc: 1.00 | Validation acc: 1.00 | Duration: 0h 8m 16s\n","Epoch 10, Acc: 1.00 | Validation acc: 1.00 | Duration: 0h 8m 16s\n","Epoch 11, Acc: 1.00 | Validation acc: 1.00 | Duration: 0h 8m 16s\n","Epoch 12, Acc: 1.00 | Validation acc: 1.00 | Duration: 0h 8m 16s\n","Epoch 13, Acc: 1.00 | Validation acc: 1.00 | Duration: 0h 8m 16s\n","Epoch 14, Acc: 1.00 | Validation acc: 1.00 | Duration: 0h 8m 16s\n","Epoch 15, Acc: 1.00 | Validation acc: 1.00 | Duration: 0h 8m 16s\n","Epoch 16, Acc: 1.00 | Validation acc: 1.00 | Duration: 0h 8m 16s\n","Epoch 17, Acc: 1.00 | Validation acc: 1.00 | Duration: 0h 8m 16s\n","Epoch 18, Acc: 1.00 | Validation acc: 1.00 | Duration: 0h 8m 16s\n","Epoch 19, Acc: 1.00 | Validation acc: 1.00 | Duration: 0h 8m 16s\n","Epoch 20, Acc: 1.00 | Validation acc: 1.00 | Duration: 0h 8m 15s\n"]}],"source":["# Train model\n","n_epochs = 20  # Define the number of epochs\n","trained_model = train_model(model, train_data_loader, val_data_loader, device, n_epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"cyS9xDrL-5jz"},"outputs":[],"source":["save_path = \"/content/drive/MyDrive/Colab_Notebooks/NLP/Project/models/\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZgyqdLuR_EBM"},"outputs":[],"source":["!cp -r $model_directory $save_path"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yfKWpZzG5CGN"},"outputs":[],"source":["def evaluate_model(model, test_loader, device):\n","    model.eval()\n","    predictions, true_labels = [], []\n","    for batch in test_loader:\n","        batch_input_ids = batch['input_ids'].to(device)\n","        batch_attention_mask = batch['attention_mask'].to(device)\n","        batch_labels = batch['labels'].to(device)\n","        with torch.no_grad():\n","            outputs = model(batch_input_ids, attention_mask=batch_attention_mask)\n","            logits = outputs[0]\n","            preds = torch.argmax(logits, dim=1)\n","        predictions.extend(preds.tolist())\n","        true_labels.extend(batch_labels.tolist())\n","    return predictions, true_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PxBYlKH05CGN"},"outputs":[],"source":["def generate_classification_report(predictions, true_labels):\n","    report = classification_report(true_labels, predictions, target_names=relevant_encoder.classes_)\n","    return report"]},{"cell_type":"code","source":["# Evaluate model\n","predictions, true_labels = evaluate_model(trained_model, train_data_loader, device)\n","report = generate_classification_report(predictions, true_labels)\n","print(report)"],"metadata":{"id":"y3A4iDFR_Nwp"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"BnY3CFXm5CGN","outputId":"085523de-1dec-425d-fed0-ff7c02d91dc7"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","  irrelevant       1.00      1.00      1.00     33992\n","    relevant       1.00      1.00      1.00     34028\n","\n","    accuracy                           1.00     68020\n","   macro avg       1.00      1.00      1.00     68020\n","weighted avg       1.00      1.00      1.00     68020\n","\n"]}],"source":["# Evaluate model\n","predictions, true_labels = evaluate_model(trained_model, test_data_loader, device)\n","report = generate_classification_report(predictions, true_labels)\n","print(report)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Z6YhAEcb5CGO"},"outputs":[],"source":["# Completing the predict_text function\n","\n","def predict_text(model, text, tokenizer, max_len, device):\n","    model.eval()\n","    encoding = tokenizer.encode_plus(\n","        text,\n","        add_special_tokens=True,\n","        max_length=max_len,\n","        return_token_type_ids=False,\n","        padding='max_length',\n","        return_attention_mask=True,\n","        return_tensors='pt',\n","        truncation=True,\n","    )\n","    input_ids = encoding['input_ids'].to(device)\n","    attention_mask = encoding['attention_mask'].to(device)\n","\n","    with torch.no_grad():\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        logits = outputs[0]\n","        prediction = torch.argmax(logits, dim=1).cpu().numpy()[0]\n","\n","    return prediction\n","\n","# Now, the complete function is provided, and the entire script is corrected. This should ensure the entire process, from data loading to prediction, works smoothly with a CSV input."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KWAcn0WO9tt9"},"outputs":[],"source":["# Load the model and tokenizer from a specified epoch\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","model_directory = \"./relevantQA_bert\"  # Adjust the path to match where you've saved the model\n","\n","load_model = BertForSequenceClassification.from_pretrained(model_directory)\n","load_model.to(device)\n","load_tokenizer = BertTokenizer.from_pretrained(model_directory)\n","load_model = load_model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"QLRJXdrT5CGO","outputId":"38e04f40-f48d-4880-da32-56742414e938"},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted class for example text: relevant\n"]}],"source":["# Example prediction\n","example_text = \"I am coughing everyday.\"\n","prediction = predict_text(load_model, example_text, load_tokenizer, max_len, device)\n","predicted_label = relevant_encoder.inverse_transform([prediction])[0]\n","print(f\"Predicted class for example text: {predicted_label}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ATtwiVdY5oRl","outputId":"effba3ab-c91f-4d5e-8b3d-b099bd309165"},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted class for example text: relevant\n"]}],"source":["# Example prediction\n","example_text = \"I like to eat apple.\"\n","prediction = predict_text(load_model, example_text, load_tokenizer, max_len, device)\n","predicted_label = relevant_encoder.inverse_transform([prediction])[0]\n","print(f\"Predicted class for example text: {predicted_label}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}